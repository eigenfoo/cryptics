{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\\n\\nimport traceback\\nimport datetime\\nimport os\\nimport re\\nimport time\\nimport random\\nimport json\\nfrom collections import defaultdict\\n\\nimport requests\\nimport bs4\\nimport numpy as np\\nimport pandas as pd\\n\\nimport ipdb\\n\\nfrom cryptic_info.parse import try_parse\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\\n\\nimport traceback\\nimport datetime\\nimport os\\nimport re\\nimport time\\nimport random\\nimport json\\nfrom collections import defaultdict\\n\\nimport requests\\nimport bs4\\nimport numpy as np\\nimport pandas as pd\\n\\nimport ipdb\\n\\nfrom cryptic_info.parse import try_parse\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black\n",
    "\n",
    "import traceback\n",
    "import datetime\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "import requests\n",
    "import bs4\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import ipdb\n",
    "\n",
    "from cryptic_info.parse import try_parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"from cryptic_info.tables import (\\n    is_parsable_table_type_1,\\n    parse_table_type_1,\\n    is_parsable_table_type_2,\\n    parse_table_type_2,\\n)\\nfrom cryptic_info.lists import (\\n    is_parsable_list_type_1,\\n    parse_list_type_1,\\n    is_parsable_list_type_2,\\n    parse_list_type_2,\\n)\\nfrom cryptic_info.utils import extract_puzzle_url\";\n",
       "                var nbb_formatted_code = \"from cryptic_info.tables import (\\n    is_parsable_table_type_1,\\n    parse_table_type_1,\\n    is_parsable_table_type_2,\\n    parse_table_type_2,\\n)\\nfrom cryptic_info.lists import (\\n    is_parsable_list_type_1,\\n    parse_list_type_1,\\n    is_parsable_list_type_2,\\n    parse_list_type_2,\\n)\\nfrom cryptic_info.utils import extract_puzzle_url\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from cryptic_info.tables import (\n",
    "    is_parsable_table_type_1,\n",
    "    parse_table_type_1,\n",
    "    is_parsable_table_type_2,\n",
    "    parse_table_type_2,\n",
    ")\n",
    "from cryptic_info.lists import (\n",
    "    is_parsable_list_type_1,\n",
    "    parse_list_type_1,\n",
    "    is_parsable_list_type_2,\n",
    "    parse_list_type_2,\n",
    ")\n",
    "from cryptic_info.utils import extract_puzzle_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"headers = {\\n    \\\"User-Agent\\\": \\\"Mozilla/5.0 (X11; Linux x86_64)\\\",\\n    \\\"Accept-Encoding\\\": \\\"gzip\\\",\\n}\";\n",
       "                var nbb_formatted_code = \"headers = {\\n    \\\"User-Agent\\\": \\\"Mozilla/5.0 (X11; Linux x86_64)\\\",\\n    \\\"Accept-Encoding\\\": \\\"gzip\\\",\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64)\",\n",
    "    \"Accept-Encoding\": \"gzip\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"# Create initial metadata JSON\\nmetadata = dict()\\n\\nmetadata[\\\"last_run\\\"] = (\\n    datetime.datetime.now().astimezone(datetime.timezone.utc).strftime(\\\"%c %Z\\\")\\n)\\nmetadata[\\\"unindexed_urls\\\"] = []\\nmetadata[\\\"indexed_urls\\\"] = []\\nmetadata[\\\"errored_urls\\\"] = []\\n\\nSITEMAP_URL = \\\"https://www.fifteensquared.net/wp-sitemap.xml\\\"\\n\\nresponse = requests.get(SITEMAP_URL, headers=headers)\\nsoup = bs4.BeautifulSoup(response.text)\\n\\n# FIXME: let's just do the most recent sitemap first...\\nsitemaps = list(\\n    reversed(\\n        [\\n            sitemap.text\\n            for sitemap in soup.find_all(\\\"sitemap\\\")\\n            if re.search(\\n                r\\\"https://www.fifteensquared.net/wp-sitemap-posts-post-10.xml\\\",\\n                sitemap.text,\\n            )\\n        ]\\n    )\\n)\\n\\nfor sitemap in sitemaps:\\n    response = requests.get(sitemap, headers=headers)\\n    soup = bs4.BeautifulSoup(response.text)\\n    urls = [url.text for url in soup.find_all(\\\"url\\\")]\\n    metadata[\\\"unindexed_urls\\\"].extend(urls)\\n\\nwith open(\\\"metadata.json\\\", \\\"w+\\\") as f:\\n    json.dump(metadata, f)\";\n",
       "                var nbb_formatted_code = \"# Create initial metadata JSON\\nmetadata = dict()\\n\\nmetadata[\\\"last_run\\\"] = (\\n    datetime.datetime.now().astimezone(datetime.timezone.utc).strftime(\\\"%c %Z\\\")\\n)\\nmetadata[\\\"unindexed_urls\\\"] = []\\nmetadata[\\\"indexed_urls\\\"] = []\\nmetadata[\\\"errored_urls\\\"] = []\\n\\nSITEMAP_URL = \\\"https://www.fifteensquared.net/wp-sitemap.xml\\\"\\n\\nresponse = requests.get(SITEMAP_URL, headers=headers)\\nsoup = bs4.BeautifulSoup(response.text)\\n\\n# FIXME: let's just do the most recent sitemap first...\\nsitemaps = list(\\n    reversed(\\n        [\\n            sitemap.text\\n            for sitemap in soup.find_all(\\\"sitemap\\\")\\n            if re.search(\\n                r\\\"https://www.fifteensquared.net/wp-sitemap-posts-post-10.xml\\\",\\n                sitemap.text,\\n            )\\n        ]\\n    )\\n)\\n\\nfor sitemap in sitemaps:\\n    response = requests.get(sitemap, headers=headers)\\n    soup = bs4.BeautifulSoup(response.text)\\n    urls = [url.text for url in soup.find_all(\\\"url\\\")]\\n    metadata[\\\"unindexed_urls\\\"].extend(urls)\\n\\nwith open(\\\"metadata.json\\\", \\\"w+\\\") as f:\\n    json.dump(metadata, f)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create initial metadata JSON\n",
    "metadata = dict()\n",
    "\n",
    "metadata[\"last_run\"] = (\n",
    "    datetime.datetime.now().astimezone(datetime.timezone.utc).strftime(\"%c %Z\")\n",
    ")\n",
    "metadata[\"unindexed_urls\"] = []\n",
    "metadata[\"indexed_urls\"] = []\n",
    "metadata[\"errored_urls\"] = []\n",
    "\n",
    "SITEMAP_URL = \"https://www.fifteensquared.net/wp-sitemap.xml\"\n",
    "\n",
    "response = requests.get(SITEMAP_URL, headers=headers)\n",
    "soup = bs4.BeautifulSoup(response.text)\n",
    "\n",
    "# FIXME: let's just do the most recent sitemap first...\n",
    "sitemaps = list(\n",
    "    reversed(\n",
    "        [\n",
    "            sitemap.text\n",
    "            for sitemap in soup.find_all(\"sitemap\")\n",
    "            if re.search(\n",
    "                r\"https://www.fifteensquared.net/wp-sitemap-posts-post-10.xml\",\n",
    "                sitemap.text,\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "for sitemap in sitemaps:\n",
    "    response = requests.get(sitemap, headers=headers)\n",
    "    soup = bs4.BeautifulSoup(response.text)\n",
    "    urls = [url.text for url in soup.find_all(\"url\")]\n",
    "    metadata[\"unindexed_urls\"].extend(urls)\n",
    "\n",
    "with open(\"metadata.json\", \"w+\") as f:\n",
    "    json.dump(metadata, f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open(\"metadata.json\", \"r\") as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "metadata[\"unindexed_urls\"] = metadata[\"unindexed_urls\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.fifteensquared.net/2020/09/08/independent-10579-kairos/\n",
      "Requested response\n",
      "Failed to parse\n",
      "Wrote metadata\n",
      "Sleeping...\n",
      "Slept for 22.98s\n",
      "==============================================================================\n",
      "https://www.fifteensquared.net/2020/09/13/everyman-3856/\n",
      "Requested response\n",
      "Parsing using parse_table_type_1\n",
      "Successfully parsed\n",
      "Wrote metadata\n",
      "Sleeping...\n",
      "Slept for 39.41s\n",
      "==============================================================================\n",
      "https://www.fifteensquared.net/2020/09/07/independent-10578-by-harold/\n",
      "Requested response\n",
      "Parsing using parse_table_type_1\n",
      "Successfully parsed\n",
      "Wrote metadata\n",
      "Sleeping...\n",
      "Slept for 31.42s\n",
      "==============================================================================\n",
      "https://www.fifteensquared.net/2020/09/17/financial-times-16574-by-julius/\n",
      "Requested response\n",
      "Parsing using parse_table_type_1\n",
      "Successfully parsed\n",
      "Wrote metadata\n",
      "Sleeping...\n",
      "Slept for 27.78s\n",
      "==============================================================================\n",
      "https://www.fifteensquared.net/2020/09/05/independent-10577-by-tyrus/\n",
      "Requested response\n",
      "Failed to parse\n",
      "Wrote metadata\n",
      "Sleeping...\n",
      "Slept for 37.63s\n",
      "==============================================================================\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 71;\n",
       "                var nbb_unformatted_code = \"while metadata[\\\"unindexed_urls\\\"]:\\n    url = metadata[\\\"unindexed_urls\\\"].pop()\\n    print(url)\\n\\n    response = requests.get(url, headers=headers)\\n    soup = bs4.BeautifulSoup(response.text)\\n    print(\\\"Requested response\\\")\\n\\n    data = None\\n    try:\\n        data = try_parse(response, url)\\n    except Exception:\\n        print(traceback.format_exc())\\n    if data is None:\\n        print(\\\"Failed to parse\\\")\\n        metadata[\\\"errored_urls\\\"].append(url)\\n    else:\\n        print(\\\"Successfully parsed\\\")\\n        data.to_csv(\\\"data.csv\\\", index=False, mode=\\\"a\\\")\\n        metadata[\\\"indexed_urls\\\"].append(url)\\n\\n    metadata[\\\"last_run\\\"] = (\\n        datetime.datetime.now().astimezone(datetime.timezone.utc).strftime(\\\"%c %Z\\\")\\n    )\\n    with open(\\\"metadata.json\\\", \\\"w\\\") as f:\\n        json.dump(metadata, f)\\n    print(\\\"Wrote metadata\\\")\\n\\n    print(\\\"Sleeping...\\\")\\n    sleep_time = random.uniform(20, 40)\\n    time.sleep(sleep_time)\\n    print(f\\\"Slept for {sleep_time:.2f}s\\\")\\n    print(78 * \\\"=\\\")\";\n",
       "                var nbb_formatted_code = \"while metadata[\\\"unindexed_urls\\\"]:\\n    url = metadata[\\\"unindexed_urls\\\"].pop()\\n    print(url)\\n\\n    response = requests.get(url, headers=headers)\\n    soup = bs4.BeautifulSoup(response.text)\\n    print(\\\"Requested response\\\")\\n\\n    data = None\\n    try:\\n        data = try_parse(response, url)\\n    except Exception:\\n        print(traceback.format_exc())\\n    if data is None:\\n        print(\\\"Failed to parse\\\")\\n        metadata[\\\"errored_urls\\\"].append(url)\\n    else:\\n        print(\\\"Successfully parsed\\\")\\n        data.to_csv(\\\"data.csv\\\", index=False, mode=\\\"a\\\")\\n        metadata[\\\"indexed_urls\\\"].append(url)\\n\\n    metadata[\\\"last_run\\\"] = (\\n        datetime.datetime.now().astimezone(datetime.timezone.utc).strftime(\\\"%c %Z\\\")\\n    )\\n    with open(\\\"metadata.json\\\", \\\"w\\\") as f:\\n        json.dump(metadata, f)\\n    print(\\\"Wrote metadata\\\")\\n\\n    print(\\\"Sleeping...\\\")\\n    sleep_time = random.uniform(20, 40)\\n    time.sleep(sleep_time)\\n    print(f\\\"Slept for {sleep_time:.2f}s\\\")\\n    print(78 * \\\"=\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "while metadata[\"unindexed_urls\"]:\n",
    "    url = metadata[\"unindexed_urls\"].pop()\n",
    "    print(url)\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = bs4.BeautifulSoup(response.text)\n",
    "    print(\"Requested response\")\n",
    "\n",
    "    data = None\n",
    "    try:\n",
    "        data = try_parse(response, url)\n",
    "    except Exception:\n",
    "        print(traceback.format_exc())\n",
    "    if data is None:\n",
    "        print(\"Failed to parse\")\n",
    "        metadata[\"errored_urls\"].append(url)\n",
    "    else:\n",
    "        print(\"Successfully parsed\")\n",
    "        data.to_csv(\"data.csv\", index=False, mode=\"a\")\n",
    "        metadata[\"indexed_urls\"].append(url)\n",
    "\n",
    "    metadata[\"last_run\"] = (\n",
    "        datetime.datetime.now().astimezone(datetime.timezone.utc).strftime(\"%c %Z\")\n",
    "    )\n",
    "    with open(\"metadata.json\", \"w\") as f:\n",
    "        json.dump(metadata, f)\n",
    "    print(\"Wrote metadata\")\n",
    "\n",
    "    print(\"Sleeping...\")\n",
    "    sleep_time = random.uniform(20, 40)\n",
    "    time.sleep(sleep_time)\n",
    "    print(f\"Slept for {sleep_time:.2f}s\")\n",
    "    print(78 * \"=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"# Tables - type 1\\n# source_url = (\\n# \\\"https://www.fifteensquared.net/2021/05/20/financial-times-16790-by-leonidas/\\\"\\n# \\\"https://www.fifteensquared.net/2021/05/21/financial-times-16791-by-buccaneer/\\\"\\n# \\\"https://www.fifteensquared.net/2021/05/21/independent-10797-by-phi/\\\"\\n# \\\"https://www.fifteensquared.net/2021/05/23/azed-no-2553-plain/\\\"\\n# \\\"https://www.fifteensquared.net/2021/05/23/everyman-3892/\\\"\\n# )\\n\\n# Tables - type 2\\n# source_url = \\\"https://www.fifteensquared.net/2021/05/17/guardian-28447-anto/\\\"\\n\\n# List - type 1\\n# source_url = (\\n# \\\"https://www.fifteensquared.net/2021/05/22/guardian-saturday-puzzle-28446-tramp/\\\"\\n# \\\"https://www.fifteensquared.net/2021/05/23/independent-on-sunday-1630-by-raich/\\\"\\n# \\\"https://www.fifteensquared.net/2021/05/19/guardian-28449-pasquale/\\\"\\n# \\\"https://www.fifteensquared.net/2021/05/17/guardian-quiptic-1122-hectence/\\\"\\n# \\\"https://www.fifteensquared.net/2021/05/16/independent-on-sunday-1629-hoskins/\\\"\\n# )\\n\\n# List - type 2\\nsource_url = (\\n    # \\\"https://www.fifteensquared.net/2021/05/20/independent-10796-by-tees/\\\"\\n    \\\"https://www.fifteensquared.net/2021/05/17/financial-times-16787-by-peto/\\\"\\n)\\n\\n# TODO: Tables - type 3???\\n# Hihoba does the hard puzzles, and formats his posts fairly inconsistently, depending on the theme...\\n# https://www.fifteensquared.net/author/hihoba/\\n# source_url = \\\"https://www.fifteensquared.net/2021/05/18/inquisitor-1698-spooky-manifestations-by-kruger/\\\"\\n\\n# TODO: Lists - type 3???\\n# source_url = \\\"https://www.fifteensquared.net/2021/05/21/guardian-cryptic-28451-puck/\\\"\\n\\n\\n# FIXME: why does the extract_definitions fail? Not urgent\\n# source_url = \\\"https://www.fifteensquared.net/2021/05/16/everyman-3891/\\\"\\n\\nresponse = requests.get(source_url, headers=headers)\";\n",
       "                var nbb_formatted_code = \"# Tables - type 1\\n# source_url = (\\n# \\\"https://www.fifteensquared.net/2021/05/20/financial-times-16790-by-leonidas/\\\"\\n# \\\"https://www.fifteensquared.net/2021/05/21/financial-times-16791-by-buccaneer/\\\"\\n# \\\"https://www.fifteensquared.net/2021/05/21/independent-10797-by-phi/\\\"\\n# \\\"https://www.fifteensquared.net/2021/05/23/azed-no-2553-plain/\\\"\\n# \\\"https://www.fifteensquared.net/2021/05/23/everyman-3892/\\\"\\n# )\\n\\n# Tables - type 2\\n# source_url = \\\"https://www.fifteensquared.net/2021/05/17/guardian-28447-anto/\\\"\\n\\n# List - type 1\\n# source_url = (\\n# \\\"https://www.fifteensquared.net/2021/05/22/guardian-saturday-puzzle-28446-tramp/\\\"\\n# \\\"https://www.fifteensquared.net/2021/05/23/independent-on-sunday-1630-by-raich/\\\"\\n# \\\"https://www.fifteensquared.net/2021/05/19/guardian-28449-pasquale/\\\"\\n# \\\"https://www.fifteensquared.net/2021/05/17/guardian-quiptic-1122-hectence/\\\"\\n# \\\"https://www.fifteensquared.net/2021/05/16/independent-on-sunday-1629-hoskins/\\\"\\n# )\\n\\n# List - type 2\\nsource_url = (\\n    # \\\"https://www.fifteensquared.net/2021/05/20/independent-10796-by-tees/\\\"\\n    \\\"https://www.fifteensquared.net/2021/05/17/financial-times-16787-by-peto/\\\"\\n)\\n\\n# TODO: Tables - type 3???\\n# Hihoba does the hard puzzles, and formats his posts fairly inconsistently, depending on the theme...\\n# https://www.fifteensquared.net/author/hihoba/\\n# source_url = \\\"https://www.fifteensquared.net/2021/05/18/inquisitor-1698-spooky-manifestations-by-kruger/\\\"\\n\\n# TODO: Lists - type 3???\\n# source_url = \\\"https://www.fifteensquared.net/2021/05/21/guardian-cryptic-28451-puck/\\\"\\n\\n\\n# FIXME: why does the extract_definitions fail? Not urgent\\n# source_url = \\\"https://www.fifteensquared.net/2021/05/16/everyman-3891/\\\"\\n\\nresponse = requests.get(source_url, headers=headers)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tables - type 1\n",
    "# source_url = (\n",
    "# \"https://www.fifteensquared.net/2021/05/20/financial-times-16790-by-leonidas/\"\n",
    "# \"https://www.fifteensquared.net/2021/05/21/financial-times-16791-by-buccaneer/\"\n",
    "# \"https://www.fifteensquared.net/2021/05/21/independent-10797-by-phi/\"\n",
    "# \"https://www.fifteensquared.net/2021/05/23/azed-no-2553-plain/\"\n",
    "# \"https://www.fifteensquared.net/2021/05/23/everyman-3892/\"\n",
    "# )\n",
    "\n",
    "# Tables - type 2\n",
    "# source_url = \"https://www.fifteensquared.net/2021/05/17/guardian-28447-anto/\"\n",
    "\n",
    "# List - type 1\n",
    "# source_url = (\n",
    "# \"https://www.fifteensquared.net/2021/05/22/guardian-saturday-puzzle-28446-tramp/\"\n",
    "# \"https://www.fifteensquared.net/2021/05/23/independent-on-sunday-1630-by-raich/\"\n",
    "# \"https://www.fifteensquared.net/2021/05/19/guardian-28449-pasquale/\"\n",
    "# \"https://www.fifteensquared.net/2021/05/17/guardian-quiptic-1122-hectence/\"\n",
    "# \"https://www.fifteensquared.net/2021/05/16/independent-on-sunday-1629-hoskins/\"\n",
    "# )\n",
    "\n",
    "# List - type 2\n",
    "# source_url = (\n",
    "    # \"https://www.fifteensquared.net/2021/05/20/independent-10796-by-tees/\"\n",
    "    # \"https://www.fifteensquared.net/2021/05/17/financial-times-16787-by-peto/\"\n",
    "# )\n",
    "\n",
    "# TODO: Tables - type 3???\n",
    "# Hihoba does the hard puzzles, and formats his posts fairly inconsistently, depending on the theme...\n",
    "# https://www.fifteensquared.net/author/hihoba/\n",
    "# source_url = \"https://www.fifteensquared.net/2021/05/18/inquisitor-1698-spooky-manifestations-by-kruger/\"\n",
    "\n",
    "# TODO: Lists - type 3???\n",
    "# source_url = \"https://www.fifteensquared.net/2021/05/21/guardian-cryptic-28451-puck/\"\n",
    "\n",
    "# FIXME: why does the extract_definitions fail? Not urgent\n",
    "# source_url = \"https://www.fifteensquared.net/2021/05/16/everyman-3891/\"\n",
    "\n",
    "response = requests.get(source_url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing using parse_list_type_2\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"data = try_parse(response, source_url)\";\n",
       "                var nbb_formatted_code = \"data = try_parse(response, source_url)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = try_parse(response, source_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
